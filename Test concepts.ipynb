{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicate hits, keep only the best one ( smaller edge ) first to come out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "def removeDuplicates(df):\n",
    "    print(\"## REMOVE DUPLICATES EDGES ##\")\n",
    "    df.sort_values('node1')\n",
    "    df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "    print(\"Lenght of the dataframe after REMOVE DUPLICATES EDGES: \" + str(len(df)))\n",
    "    if len(df) == 0:\n",
    "        print(\"ERROR: Lenght of the dataframe = 0 - I can't generate the gephi/cytoscape network\")\n",
    "        exit()\n",
    "    print('------------------------------')\n",
    "    return(df)\n",
    "\n",
    "\n",
    "def removeSelfHit(df):\n",
    "    print(\"## REMOVE SELF HITS ##\")\n",
    "    \"\"\" this function removes the BLAST self hits \"\"\"\n",
    "    to_drop = []\n",
    "    for i in range(len(df)):\n",
    "        node1 = df.iloc[i]['node1']\n",
    "        node2 = df.iloc[i]['node2']\n",
    "        if str(node1) == str(node2):\n",
    "            to_drop.append(i)\n",
    "    df = df.drop(df.index[to_drop])\n",
    "    print(\"Lenght of the dataframe after REMOVE SELF HITS: \" + str(len(df)))\n",
    "    if len(df) == 0:\n",
    "        print(\"ERROR: Lenght of the dataframe = 0 - I can't generate the gephi/cytoscape network\")\n",
    "        exit()\n",
    "    print('------------------------------')\n",
    "    return(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    node1  node2   eval\n",
      "0   node1  node2  0.222\n",
      "1   node1  node2  0.400\n",
      "2   node1  node2  9.000\n",
      "3   node2  node1  3.000\n",
      "4   node2  node1  9.000\n",
      "5   node2  node1  9.000\n",
      "6   node2  node1  9.000\n",
      "7   node2  node1  9.000\n",
      "8   node1  node2  0.400\n",
      "9   node1  node2  0.400\n",
      "10  node1  node2  0.400\n",
      "11  node1  node2  0.400\n",
      "12  node1  node1  1.000\n",
      "13  node2  node2  2.000\n",
      "\n",
      "LEN DF 14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inputf = \"test.tsv\"\n",
    "df = pd.read_csv(inputf, sep='\\t', header=None)\n",
    "df.columns = [\"node1\",\"node2\",\"eval\"]\n",
    "\n",
    "print(df)\n",
    "print(\"\\nLEN DF\",len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## REMOVE SELF HITS ##\n",
      "Lenght of the dataframe after REMOVE SELF HITS: 12\n",
      "------------------------------\n",
      "    node1  node2   eval\n",
      "0   node1  node2  0.222\n",
      "1   node1  node2  0.400\n",
      "2   node1  node2  9.000\n",
      "3   node2  node1  3.000\n",
      "4   node2  node1  9.000\n",
      "5   node2  node1  9.000\n",
      "6   node2  node1  9.000\n",
      "7   node2  node1  9.000\n",
      "8   node1  node2  0.400\n",
      "9   node1  node2  0.400\n",
      "10  node1  node2  0.400\n",
      "11  node1  node2  0.400\n"
     ]
    }
   ],
   "source": [
    "df = removeSelfHit(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## REMOVE DUPLICATES EDGES ##\n",
      "Lenght of the dataframe after REMOVE DUPLICATES EDGES: 5\n",
      "------------------------------\n",
      "   node1  node2   eval\n",
      "0  node1  node2  0.222\n",
      "1  node1  node2  0.400\n",
      "2  node1  node2  9.000\n",
      "3  node2  node1  3.000\n",
      "4  node2  node1  9.000\n"
     ]
    }
   ],
   "source": [
    "df = removeDuplicates(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeBigEval(df):\n",
    "    print(\"## KEEP ONLY HIT WITH SMALLER EVAL ##\")\n",
    "    df.sort_values('eval')\n",
    "    df.drop_duplicates(subset = ['node1', 'node2'], keep=\"first\", inplace=True)\n",
    "    print(\"Lenght of the dataframe after KEEP ONLY HIT WITH SMALLER EVAL: \" + str(len(df)))\n",
    "    if len(df) == 0:\n",
    "        print(\"ERROR: Lenght of the dataframe = 0 - I can't generate the gephi/cytoscape network\")\n",
    "        exit()\n",
    "    print('------------------------------')\n",
    "    return(df)\n",
    "\n",
    "def evalToForce(df):\n",
    "    print(\"Converting Evalues to Forces\")\n",
    "    x = df['eval'].values\n",
    "    listForces = []\n",
    "    min = numpy.amin(x)\n",
    "    max = numpy.amax(x)\n",
    "    print(f\"Min Evalue {min}, Max Evalue {max}\")\n",
    "    for eval in x:\n",
    "        force = max - (eval - min)\n",
    "        listForces.append(force)\n",
    "    df['eval'] = listForces\n",
    "    return df\n",
    "\n",
    "def normalize(df):\n",
    "    ''' CHECKED ---- '''\n",
    "    print(\"## NORMALIZING EDGES ##\")\n",
    "    \"\"\" Normalisation of the column eval \"\"\"\n",
    "    x = df['eval']#.values.astype(float)\n",
    "    x = x.to_frame()\n",
    "    #scaler = preprocessing.StandardScaler()\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "    df_normalized = pd.DataFrame(x_scaled)\n",
    "    dflist = df_normalized.values\n",
    "    df['eval'] = dflist\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## NORMALIZING EDGES ##\n",
      "   node1  node2      eval\n",
      "0  node1  node2  0.000000\n",
      "1  node1  node2  0.020278\n",
      "2  node1  node2  1.000000\n",
      "3  node2  node1  0.316473\n",
      "4  node2  node1  1.000000\n"
     ]
    }
   ],
   "source": [
    "df = normalize(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## KEEP ONLY HIT WITH SMALLER EVAL ##\n",
      "Lenght of the dataframe after KEEP ONLY HIT WITH SMALLER EVAL: 2\n",
      "------------------------------\n",
      "   node1  node2   eval\n",
      "0  node1  node2  0.222\n",
      "3  node2  node1  3.000\n"
     ]
    }
   ],
   "source": [
    "df = removeBigEval(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Evalues to Forces\n",
      "Min Evalue 0.222, Max Evalue 3.0\n",
      "   node1  node2   eval\n",
      "0  node1  node2  3.000\n",
      "3  node2  node1  0.222\n"
     ]
    }
   ],
   "source": [
    "df = evalToForce(df)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
